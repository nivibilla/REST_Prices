{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"./Data/processed/\").mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = 'DAY'\n",
    "\n",
    "ApiKeys = []\n",
    "e = open(\"APIKEYS.txt\", \"r\")\n",
    "for y in e:\n",
    "    ApiKeys.append(y.strip())\n",
    "e.close()\n",
    "\n",
    "epicList = []\n",
    "e = open(\"epics.txt\", \"r\")\n",
    "for y in e:\n",
    "    epicList.append(y.strip())\n",
    "e.close()\n",
    "\n",
    "\n",
    "username = 'eastwind'\n",
    "password = 'Eastwind1!'\n",
    "\n",
    "initialStart = '2015-01-01'\n",
    "initialEnd = '2021-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createLog():\n",
    "    print(\"Creating Log\")\n",
    "    log = []\n",
    "    for epic in epicList:\n",
    "        log.append([epic, 'none', 'none'])\n",
    "    log = pd.DataFrame(log, columns=['name', 'from', 'to'])\n",
    "    log.to_csv('./log.txt', index=None)\n",
    "\n",
    "def readLog():\n",
    "    try:\n",
    "        log = pd.read_csv('./log.txt', index_col=0)\n",
    "    except FileNotFoundError:\n",
    "        createLog()\n",
    "        return readLog()\n",
    "    return log\n",
    "\n",
    "def writeLog(log):\n",
    "    log.to_csv('./log.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def login(api):\n",
    "    try:\n",
    "        url = 'https://demo-api.ig.com/gateway/deal/session'\n",
    "\n",
    "        s = requests.Session()\n",
    "        s.headers = {'Content-Type': 'application/json; charset=UTF-8',\n",
    "                        'Accept': 'application/json; charset=UTF-8', 'VERSION': '2', 'X-IG-API-KEY': api}\n",
    "        data = {'identifier': username, 'password': password}\n",
    "        r = s.post(url, json=data)\n",
    "        s.headers.update({'X-SECURITY-TOKEN': r.headers['X-SECURITY-TOKEN'], 'CST': r.headers['CST']})\n",
    "        s.headers.update({'Version': '3'})\n",
    "    except:\n",
    "        print(r)\n",
    "        print(s)\n",
    "        return\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDF(EPIC, start, end, s):\n",
    "    try:\n",
    "        nameURL = 'https://demo-api.ig.com/gateway/deal/markets/' + EPIC\n",
    "\n",
    "        address = [\"https://demo-api.ig.com/gateway/deal/prices/\", EPIC, \"?resolution=\", resolution,\n",
    "                    \"&from=\", str(start), \"&to=\", str(end), \"&pageSize=0\"]\n",
    "        URL = ''.join(address)\n",
    "\n",
    "        prices = s.get(URL)\n",
    "        prices = prices.text\n",
    "\n",
    "\n",
    "        nameData = s.get(nameURL)\n",
    "        nameData = nameData.text\n",
    "\n",
    "        nameData = json.loads(nameData)\n",
    "        priceData = json.loads(prices)\n",
    "\n",
    "        name = nameData['instrument']['marketId']\n",
    "\n",
    "        if name == None:\n",
    "            return \"failed\"\n",
    "\n",
    "        for price in priceData['prices']:\n",
    "            price['openPrice'] = price['openPrice']['ask']\n",
    "            price['closePrice'] = price['closePrice']['ask']\n",
    "            price['highPrice'] = price['highPrice']['ask']\n",
    "            price['lowPrice'] = price['lowPrice']['ask']\n",
    "\n",
    "        df = pd.DataFrame(priceData['prices'])\n",
    "        df.columns = ['time', 'utcTime', 'open', 'close', 'high', 'low', 'volume']\n",
    "        df.drop(['utcTime'], axis=1, inplace=True)\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        df['time'] = df.time.dt.strftime('%Y%m%d').astype(int)\n",
    "        df['name'] = name\n",
    "        df = df[['name', 'time', 'open', 'high', 'low', 'close', 'volume']]\n",
    "    except:\n",
    "        try:\n",
    "            return \"failed\"\n",
    "        except:\n",
    "            pass\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPriceData(epicList, combined, api, s):\n",
    "    \n",
    "    failed = []\n",
    "\n",
    "    for epic in tqdm(epicList):\n",
    "        if log.loc[epic]['from'] == \"none\":\n",
    "            newdf = getDF(epic, initialStart, initialEnd, s)\n",
    "            if type(newdf) == str:\n",
    "                failed.append(epic)\n",
    "                continue\n",
    "            else:\n",
    "                combined = pd.concat([combined, newdf], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "                log.loc[epic]['from'] = initialStart\n",
    "                log.loc[epic]['to'] = initialEnd\n",
    "        else:\n",
    "            toDate = (datetime.datetime.today() + datetime.timedelta(-1)).strftime(\"%Y-%m-%d\")\n",
    "            if log.loc[epic]['to'] == toDate:\n",
    "                continue\n",
    "            fromDate = pd.to_datetime(log.loc[epic]['to']).strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "            newdf = getDF(epic, fromDate, toDate, s)\n",
    "            if type(newdf) == str:\n",
    "                failed.append(epic)\n",
    "                continue\n",
    "            else:\n",
    "                combined = pd.concat([combined, newdf], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "                log.loc[epic]['to'] = toDate\n",
    "        \n",
    "    if len(failed) != 0:\n",
    "        try:\n",
    "            api = ApiKeys[ApiKeys.index(api) + 1]\n",
    "            s = login(api)\n",
    "        except IndexError:\n",
    "            print(\"No More API Keys Left To Try\")\n",
    "            writeLog(log)\n",
    "            return combined, failed\n",
    "\n",
    "        combined, failed = getPriceData(failed, combined, api, s)\n",
    "    \n",
    "    writeLog(log)\n",
    "    return combined, failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getApiKey():\n",
    "    api = ApiKeys[0]\n",
    "    return api\n",
    "\n",
    "def setup(api):\n",
    "    s = login(api)\n",
    "\n",
    "    log = readLog()\n",
    "    return s, log\n",
    "\n",
    "def run(api, s, log):\n",
    "    \n",
    "    existingProcessedData = os.listdir('./Data/processed/')\n",
    "    combined = pd.DataFrame(columns=['name', 'time', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    print(\"Loading Previously Downloaded Data\")\n",
    "    for path in tqdm(existingProcessedData):\n",
    "        combined = pd.concat([combined, pd.read_csv('./Data/processed/' + path, names=['name', 'time', 'open', 'high', 'low', 'close', 'volume'])], ignore_index=True).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    combined, failed = getPriceData(epicList, combined, api, s)\n",
    "    combined.sort_values(by=['time', 'name'], inplace=True)\n",
    "    combined.reset_index(drop=True, inplace=True)\n",
    "    days = np.unique(combined.time)\n",
    "\n",
    "    print(\"Writing New Data\")\n",
    "    for day in tqdm(days):\n",
    "        combined[combined.time == day].to_csv('./Data/processed/' + str(day) + '.txt', index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = getApiKey()\n",
    "s, log = setup(api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "0it [00:00, ?it/s]\n",
      "  0%|          | 0/14 [00:00<?, ?it/s]Loading Previously Downloaded Data\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.05it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.88it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.76it/s]\n",
      "100%|██████████| 10/10 [00:04<00:00,  2.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  2.03it/s]\n",
      "  2%|▏         | 36/1872 [00:00<00:05, 349.93it/s]Writing New Data\n",
      "100%|██████████| 1872/1872 [00:05<00:00, 359.59it/s]\n"
     ]
    }
   ],
   "source": [
    "run(api, s, log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  1%|▏         | 27/1872 [00:00<00:06, 265.58it/s]Loading Previously Downloaded Data\n",
      "100%|██████████| 1872/1872 [00:19<00:00, 96.28it/s]\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.51it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 2821.60it/s]\n",
      "<Response [403]>\n",
      "<requests.sessions.Session object at 0x00000255C13A6A00>\n",
      "100%|██████████| 14/14 [00:03<00:00,  4.45it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  5.46it/s]\n",
      "100%|██████████| 14/14 [00:02<00:00,  4.83it/s]\n",
      "100%|██████████| 5/5 [00:00<00:00,  7.02it/s]\n",
      "  2%|▏         | 37/1926 [00:00<00:05, 362.80it/s]Writing New Data\n",
      "100%|██████████| 1926/1926 [00:05<00:00, 363.19it/s]\n"
     ]
    }
   ],
   "source": [
    "api = getApiKey()\n",
    "run(api, s, log)"
   ]
  }
 ]
}